{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from src.normalize_split import inverse_minmax_scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KrankenDataSet(Dataset):\n",
    "    def __init__(self, input_data_pth, xlabel, ylabel):\n",
    "        data = np.load(input_data_pth)\n",
    "        self.X = torch.from_numpy(data[xlabel]).to(torch.float)\n",
    "        self.y = torch.from_numpy(data[ylabel]).to(torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return self.X[idx, ...], self.y[idx, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=50, kernel_size=6, stride=1),\n",
    "            nn.BatchNorm1d(num_features=50),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.attn_layer1 = nn.MultiheadAttention(\n",
    "            embed_dim = 85,\n",
    "            num_heads = 5,\n",
    "            dropout = 0.2,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.conv_layer2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=50, out_channels=100, kernel_size=7, stride=2),\n",
    "            nn.BatchNorm1d(num_features=100),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.attn_layer2 = nn.MultiheadAttention(\n",
    "            embed_dim = 40,\n",
    "            num_heads = 4,\n",
    "            dropout = 0.2,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.flatten_and_transform = nn.Sequential(\n",
    "            nn.Flatten(1, 2),  # (M*N, 100 * 40)  -> (M*N, 200)\n",
    "            nn.Linear(in_features=4000, out_features=200)\n",
    "        )\n",
    "\n",
    "        self.attn_layer3 = nn.MultiheadAttention(\n",
    "            embed_dim = 200,\n",
    "            num_heads = 5,\n",
    "            dropout = 0.2,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.linear_layer = nn.Sequential(\n",
    "            nn.Linear(in_features=200, out_features=50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=50, out_features=1),\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X: (M, N, time)\n",
    "        M, N, _ = X.shape\n",
    "        out = torch.flatten(X, 0, 1)  # (M, N, time) -> (M*N, time)\n",
    "        out = torch.unsqueeze(out, dim=1)  # -> (M*N, 1, time)\n",
    "        out = self.conv_layer1(out)  # -> (M*N, 50, 85)\n",
    "        out, _ = self.attn_layer1(out, out, out, need_weights = False, average_attn_weights = False)  # -> (M*N, 50, 85)\n",
    "        out = self.conv_layer2(out)  # -> (M*N, 100, 40)\n",
    "        out, _ = self.attn_layer2(out, out, out, need_weights = False, average_attn_weights = False)  # -> (M*N, 100, 40)\n",
    "        out = self.flatten_and_transform(out)  # -> (M*N, 200)\n",
    "        out = out.reshape(M, N, out.shape[1])  # -> (M, N, 200)\n",
    "        out, _ = self.attn_layer3(out, out, out, need_weights = False, average_attn_weights = False)  # -> (M, N, 200)\n",
    "        out = self.linear_layer(out)  # -> (M, N, 1)\n",
    "\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CryptoTrainer:\n",
    "    def __init__(self, lr, minmax_pth=None):\n",
    "        self.lr = lr\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.model = PriceNet()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "        self.mins = None\n",
    "        self.maxs = None\n",
    "        if minmax_pth:\n",
    "            minmax_df = pd.read_csv(minmax_pth)\n",
    "            self.mins = minmax_df['mins'].to_numpy().reshape(1, -1, 1)\n",
    "            self.maxs = minmax_df['maxs'].to_numpy().reshape(1, -1, 1)\n",
    "\n",
    "\n",
    "    def forward_pass(self, X, y):\n",
    "        y_pred = self.model(X)\n",
    "        loss = self.criterion(y_pred, y)\n",
    "        return loss\n",
    "    \n",
    "    def test(self, X_test, y_test):\n",
    "        with torch.no_grad():\n",
    "            test_loss = self.forward_pass(X_test, y_test)\n",
    "        return test_loss.item()  \n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        train_loss = self.forward_pass(X_train, y_train)\n",
    "        train_loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "        return train_loss.item()\n",
    "    \n",
    "    def eval(self, X_test, y_test):\n",
    "        assert (self.mins is not None) and (self.maxs is not None)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred = self.model(X_test)\n",
    "        \n",
    "        x_test_ori = inverse_minmax_scale(X_test[:, :, [-1]].numpy(), self.mins, self.maxs)\n",
    "        y_test_ori = inverse_minmax_scale(y_test.numpy(), self.mins, self.maxs)\n",
    "        y_pred_ori = inverse_minmax_scale(y_pred.numpy(), self.mins, self.maxs)\n",
    "        \n",
    "        # Compute fraction change\n",
    "        pred_frac = (y_pred_ori - x_test_ori) / x_test_ori\n",
    "        real_frac = (y_test_ori - x_test_ori) / x_test_ori\n",
    "        weighting = np.abs(pred_frac)/np.sum(np.abs(pred_frac), axis=1).reshape(pred_frac.shape[0], 1, 1)\n",
    "        aver_winrate = np.mean(np.sum(np.sign(pred_frac) * real_frac * weighting, axis=1))\n",
    "        return aver_winrate, (x_test_ori, y_test_ori, y_pred_ori)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = KrankenDataSet('data/train_test_data.npz', xlabel='X_train', ylabel='y_train')\n",
    "dataset_test = KrankenDataSet('data/train_test_data.npz', xlabel='X_test', ylabel='y_test')\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=len(dataset_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:16<03:57, 17.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07124023139476776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:33<03:40, 16.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.047896623611450195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [00:49<03:18, 16.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04241904616355896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [01:05<02:59, 16.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.032003115862607956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [01:22<02:42, 16.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03154659643769264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [01:37<02:24, 16.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03552369773387909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [01:53<02:08, 16.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03413328155875206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [02:09<01:51, 15.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03411031514406204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [02:24<01:34, 15.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03136496990919113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [02:40<01:18, 15.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.035777222365140915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [02:56<01:02, 15.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02812858298420906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [03:11<00:47, 15.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03479861095547676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [03:27<00:31, 15.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030077047646045685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [03:43<00:15, 15.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02979174815118313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:00<00:00, 16.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02270025946199894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = CryptoTrainer(lr=1e-4, minmax_pth='data/minmax.csv')\n",
    "\n",
    "trainer.model.train()\n",
    "for X_train, y_train in tqdm(dataloader_train):\n",
    "    train_loss = trainer.train(X_train, y_train)\n",
    "\n",
    "trainer.model.eval()\n",
    "for X_test, y_test in tqdm(dataloader_test):\n",
    "    test_loss = trainer.test(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = next(iter(dataloader_test))\n",
    "trainer.model.eval()\n",
    "aver_winrate, (x_test_ori, y_test_ori, y_pred_ori) = trainer.eval(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_frac = (y_pred_ori - x_test_ori) / x_test_ori\n",
    "real_frac = (y_test_ori - x_test_ori) / x_test_ori\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021837632771131207"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.00437483],\n",
       "        [0.00507741],\n",
       "        [0.00569763],\n",
       "        ...,\n",
       "        [0.00705542],\n",
       "        [0.00042331],\n",
       "        [0.00536689]],\n",
       "\n",
       "       [[0.0044147 ],\n",
       "        [0.00502358],\n",
       "        [0.0057725 ],\n",
       "        ...,\n",
       "        [0.0069998 ],\n",
       "        [0.0004448 ],\n",
       "        [0.00597047]],\n",
       "\n",
       "       [[0.00411723],\n",
       "        [0.00502834],\n",
       "        [0.00558712],\n",
       "        ...,\n",
       "        [0.0069154 ],\n",
       "        [0.00020404],\n",
       "        [0.00534146]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.00410947],\n",
       "        [0.00466513],\n",
       "        [0.00592065],\n",
       "        ...,\n",
       "        [0.00847674],\n",
       "        [0.00101272],\n",
       "        [0.00689551]],\n",
       "\n",
       "       [[0.00403248],\n",
       "        [0.00495512],\n",
       "        [0.00585989],\n",
       "        ...,\n",
       "        [0.00850402],\n",
       "        [0.0012607 ],\n",
       "        [0.00707504]],\n",
       "\n",
       "       [[0.00427081],\n",
       "        [0.00497449],\n",
       "        [0.00588298],\n",
       "        ...,\n",
       "        [0.00845039],\n",
       "        [0.0020606 ],\n",
       "        [0.00690689]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
